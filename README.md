Deepfake audio refers to synthetically generated or manipulated voice recordings that mimic real human speech using AI techniques. Detecting deepfake audio is crucial for preventing misinformation, fraud, and identity theft.
<pre><code>&lt; # ğŸ•µï¸â€â™‚ï¸ Audio Deepfake Detection [![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE) [![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/) [![Build](https://img.shields.io/badge/build-passing-brightgreen.svg)]() A project focused on detecting deepfake audio using both traditional machine learning classifiers and deep learning models like CNNs. --- ## ğŸ“š Table of Contents - [ğŸš€ Project Overview](#-project-overview) - [ğŸ§  Models Used](#-models-used) - [ğŸ“ Project Structure](#-project-structure) - [ğŸ”§ Installation](#-installation) - [âš™ï¸ Usage](#ï¸-usage) - [ğŸ“Š Results](#-results) - [ğŸ“ License](#-license) - [ğŸ™ Acknowledgements](#-acknowledgements) --- ## ğŸš€ Project Overview This repository contains an **Audio Deepfake Detection** system trained to distinguish between real and fake audio clips. The system utilizes a combination of classical machine learning classifiers and a CNN-based model enhanced with early stopping and learning rate scheduling techniques. --- ## ğŸ§  Models Used ### ğŸ”¢ Classical ML Models (code1 and code2) Implemented using `scikit-learn` and `xgboost`: - MLPClassifier (âœ… Best performing model) - Decision Tree - Extra Trees - AdaBoost - Gradient Boosting - XGBoost - QDA (Quadratic Discriminant Analysis) ### ğŸ§  Deep Learning Model (code3 and code4) A **Convolutional Neural Network (CNN)** trained on extracted audio features such as MFCCs or spectrograms. Features: - Early stopping - Learning rate scheduler - Regularization and dropout --- ## ğŸ“ Project Structure ``` â”œâ”€â”€ code1/ â”‚ â””â”€â”€ classical_ml_training.py â”œâ”€â”€ code2/ â”‚ â””â”€â”€ feature_extraction.py â”œâ”€â”€ code3/ â”‚ â””â”€â”€ cnn_model.py â”œâ”€â”€ code4/ â”‚ â””â”€â”€ cnn_training_utils.py â”œâ”€â”€ data/ â”‚ â”œâ”€â”€ real/ â”‚ â””â”€â”€ fake/ â”œâ”€â”€ README.md â””â”€â”€ requirements.txt ``` --- ## ğŸ”§ Installation 1. Clone the repository: Â¿Â¿Â¿bash git clone https://github.com/your-username/audio-deepfake-detection.git cd audio-deepfake-detection Â¿Â¿Â¿ 2. Install the dependencies: Â¿Â¿Â¿bash pip install -r requirements.txt Â¿Â¿Â¿ --- ## âš™ï¸ Usage ### ğŸ§ª Train Classical Models Â¿Â¿Â¿bash python code1/classical_ml_training.py Â¿Â¿Â¿ ### ğŸ§  Train CNN Model Â¿Â¿Â¿bash python code3/cnn_model.py Â¿Â¿Â¿ Input audio files must be preprocessed into feature vectors or spectrogram images before training. --- ## ğŸ“Š Results | Model | Accuracy | |----------------------|----------| | MLPClassifier | â­ **Highest** | | Decision Tree | - | | Extra Trees | - | | AdaBoost | - | | Gradient Boosting | - | | XGBoost | - | | QDA | - | | CNN | (To be filled) | --- ## ğŸ“ License This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details. --- ## ğŸ™ Acknowledgements - Inspired by recent advancements in deepfake detection - Leveraged scikit-learn and TensorFlow/PyTorch for model development &gt; </code></pre>
